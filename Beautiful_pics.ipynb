{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs \n",
    "import os\n",
    "import requests\n",
    "import re \n",
    "import datetime\n",
    "url = 'https://www.ptt.cc/bbs/Beauty/index.html'\n",
    "my_cookies = { 'cookie':' _ga=GA1.2.243592888.1551752918; __cfduid=de3e03e1c1c1d9d267c43f0da9167e12a1583417355; _gid=GA1.2.1765845257.1583765682; over18=1' }\n",
    "request = requests.get( url , cookies = my_cookies )\n",
    "html = bs( request.text )\n",
    "#print(html.prettify())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles(  html, pages ):\n",
    "    pre_url = html.find_all( 'a', class_=\"btn wide\" )[1]['href'] \n",
    "    pre_url = 'https://www.ptt.cc/'+pre_url\n",
    "    articles = html.find_all('div',\"r-ent\")\n",
    "    for doc in articles:\n",
    "        push_string = doc.find( 'div',\"nrec\" ).text\n",
    "        push_count = 0\n",
    "        if push_string:\n",
    "            try:\n",
    "                push_count = int( push_string )\n",
    "            except ValueError:\n",
    "                if push_string == \"爆\":\n",
    "                    push_count = 99\n",
    "                else:\n",
    "                    push_count = -10\n",
    "        if push_count > 10:\n",
    "            if doc.find( 'a' )==None:\n",
    "                break\n",
    "            name = doc.find( 'a' ).text\n",
    "            #print(name)\n",
    "            doc_url = doc.find( 'a' )['href']\n",
    "            if name[1] == '正':\n",
    "                pages.append( { 'name':name, 'url':doc_url } )\n",
    "    return pages, pre_url\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pic( pages ):\n",
    "    for page in pages:\n",
    "        delete_chars = '\\/:*?\"<>|.'\n",
    "        for c in delete_chars:\n",
    "            page['name'] = page['name'].replace(c,'')\n",
    "        os.makedirs( './pic/'+page['name'].strip(), exist_ok = True )\n",
    "        request = requests.get( 'https://www.ptt.cc/'+page['url'], cookies = my_cookies )\n",
    "        html = bs( request.text )\n",
    "        pics = html.find_all( 'a', {'href':re.compile('https://(imgur|i\\.imgur)\\.com/.......\\.jpg')} )        \n",
    "        for pic in pics:\n",
    "            pic_name = pic.get_text().split('/')[-1]            \n",
    "            with open( './pic/'+page['name'].strip()+'/'+pic_name, 'wb' ) as f:\n",
    "                r = requests.get( pic.get_text() )\n",
    "                f.write( r.content )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    os.makedirs('./pic', exist_ok = True)\n",
    "    pages = []\n",
    "    while len(pages) < 10:\n",
    "        pages, pre_url = get_articles( html, pages ) \n",
    "        request = requests.get( pre_url, cookies = my_cookies )\n",
    "        html = bs( request.text )\n",
    "    download_pic( pages )\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
